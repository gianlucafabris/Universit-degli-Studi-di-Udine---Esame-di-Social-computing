{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac2de1e3-f156-4ade-9f49-552925403a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import os\n",
    "import json\n",
    "import pandas\n",
    "import string\n",
    "import random\n",
    "import csv\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "344fbced-7ea8-47ce-8221-27263d602d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cartella dei csv\n",
    "csv_dir = 'Crowd_frame/data/result/secondo_progetto_social_computing/Dataframe/'\n",
    "\n",
    "def serialize_json(folder, filename, data):\n",
    "    # Se la cartella non esiste la creo\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    with open(f\"{folder}/{filename}\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "        f.close()\n",
    "    print(f\"Data serialized to path: {folder}/{filename}\")\n",
    "\n",
    "# Lettura file JSON da locale\n",
    "def read_json(path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf8\") as file:\n",
    "            data = json.load(file, object_hook = lambda d: {int(k) if k.lstrip('-').isdigit() else k: v for k, v in d.items()}) # object_hook per convertire le stringhe numeriche in numeri (es. id del follower)\n",
    "        print(f\"Data read from path: {path}\")\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"No data found at path: {path}\")\n",
    "        return {}\n",
    "\n",
    "def id_generator(size=11, chars=string.ascii_uppercase):\n",
    "    return ''.join(random.choice(chars) for _ in range(size))\n",
    "\n",
    "# Controllo la riga in cui sto inserendo l'elemento per evitare di inserire elementi provenienti dalla stessa riga del csv\n",
    "def check_row(hits, random_row, x):\n",
    "    for i in range(3):\n",
    "        if(hits[random_row][i] != 0 and hits[random_row][i].type[:1] == 'G'):\n",
    "            if(hits[random_row][(i+1)%3] != 0 and hits[random_row][(i+1)%3].type[:1] == 'E'):\n",
    "                if(int(hits[random_row][(i+1)%3].type[1:]) - 1 == x):\n",
    "                    return False\n",
    "            if(hits[random_row][(i+2)%3] != 0 and hits[random_row][(i+2)%3].type[:1] == 'E'):\n",
    "                if(int(hits[random_row][(i+2)%3].type[1:]) - 1 == x):\n",
    "                    return False\n",
    "            else:\n",
    "                return True\n",
    "\n",
    "# Funzione per il percent agreemnt del Explanation quality\n",
    "def in_same_interval(values, ground, compared, n):\n",
    "    Lie = range(0,19)\n",
    "    false = range(20,35)\n",
    "    Barely_True = range(36,50)\n",
    "    Half_true = range(51,65)\n",
    "    Mostly_true = range(66,80)\n",
    "    true = range(81,100)\n",
    "    \n",
    "    if(ground in Lie and compared in Lie):\n",
    "        values.loc['Statement ' + str(n), 'Explanation quality'] += 1\n",
    "    elif(ground in false and compared in false):\n",
    "        values.loc['Statement ' + str(n), 'Explanation quality'] += 1\n",
    "    elif(ground in Barely_True and compared in Barely_True):\n",
    "        values.loc['Statement ' + str(n), 'Explanation quality'] += 1\n",
    "    elif(ground in Half_true and compared in Half_true):\n",
    "        values.loc['Statement ' + str(n), 'Explanation quality'] += 1\n",
    "    elif(ground in Mostly_true and compared in Mostly_true):\n",
    "        values.loc['Statement ' + str(n), 'Explanation quality'] += 1\n",
    "    elif(ground in true and compared in true):\n",
    "        values.loc['Statement ' + str(n), 'Explanation quality'] += 1\n",
    "\n",
    "# funione per calcolare la media delle dimensioni qualitative delle explanation\n",
    "def average_explanation_quality_values (average_explanation_values, explanation, string):\n",
    "    for i in range (len(explanation.index)):\n",
    "        average_explanation_values.loc['Truthfulness 1', 'Explanation ' + string] += workers_answers.loc[explanation.index.values[i], 'doc_truthfulness1_value']\n",
    "        average_explanation_values.loc['Truthfulness 2', 'Explanation ' + string] += workers_answers.loc[explanation.index.values[i], 'doc_truthfulness2_value']\n",
    "        average_explanation_values.loc['Explanation quality', 'Explanation ' + string] += workers_answers.loc[explanation.index.values[i], 'doc_explanationquality_value']\n",
    "\n",
    "    average_explanation_values.loc['Truthfulness 1', 'Explanation ' + string] /= len(explanation.index)\n",
    "    average_explanation_values.loc['Truthfulness 2', 'Explanation ' + string] /= len(explanation.index)\n",
    "    average_explanation_values.loc['Explanation quality', 'Explanation ' + string] /= len(explanation.index)\n",
    "\n",
    "# funione per calcolare la media della lunghezza delle note divise per explanation\n",
    "def average_text_percentage(text_percentage, explanation, string):\n",
    "\n",
    "    for i in range (len(explanation.index)):\n",
    "        text_percentage.loc['percentage', 'Explanation ' + string] += len(workers_notes.loc[explanation.index.values[i], 'note_text_current'])\n",
    "\n",
    "    text_percentage.loc['percentage', 'Explanation ' + string] /= len(explanation.index)\n",
    "\n",
    "    if(len(explanation) > 0):\n",
    "        text_percentage.loc['percentage', 'Explanation ' + string] /= len(workers_notes.loc[explanation.index.values[0], 'note_text_right']) + workers_notes.loc[explanation.index.values[0], 'note_index_end']\n",
    "\n",
    "# funzione per assegnare explanation, statement, label e id corretti in base alle note, alcuni\n",
    "# worker avevano dati riguardanti gli elementi delle HITs in workers_answers che non combaciavano \n",
    "# con i dati in workers_notes, quindi siamo risaliti alle explanation, statement, label e id corretti \n",
    "# grazie alle note   \n",
    "def answers_fix(n, x, new_workers_answers, new_workers_notes, fever):\n",
    "    while(n < x):\n",
    "        explanation = new_workers_notes.loc[n, 'note_text_left'] + new_workers_notes.loc[n, 'note_text_raw'] + new_workers_notes.loc[n, 'note_text_right']      \n",
    "        if(explanation == fever.loc[0, 'explanation_human']):            \n",
    "            new_workers_answers.loc[n, 'doc_id'] = 183468\n",
    "            new_workers_answers.loc[n, 'doc_statement'] = fever.loc[0, 'statement']\n",
    "            new_workers_answers.loc[n, 'doc_explanation'] = fever.loc[0, 'explanation_human']\n",
    "            new_workers_answers.loc[n, 'doc_label'] = fever.loc[0, 'label']\n",
    "        elif(explanation == fever.loc[1, 'explanation_human']):            \n",
    "            new_workers_answers.loc[n, 'doc_id'] = 185415\n",
    "            new_workers_answers.loc[n, 'doc_statement'] = fever.loc[1, 'statement']\n",
    "            new_workers_answers.loc[n, 'doc_explanation'] = fever.loc[1, 'explanation_human']\n",
    "            new_workers_answers.loc[n, 'doc_label'] = fever.loc[1, 'label']\n",
    "        elif(explanation == fever.loc[2, 'explanation_human']):            \n",
    "            new_workers_answers.loc[n, 'doc_id'] = 63527\n",
    "            new_workers_answers.loc[n, 'doc_statement'] = fever.loc[2, 'statement']\n",
    "            new_workers_answers.loc[n, 'doc_explanation'] = fever.loc[2, 'explanation_human']\n",
    "            new_workers_answers.loc[n, 'doc_label'] = fever.loc[2, 'label']\n",
    "        elif(explanation == fever.loc[0, 'explanation_model']):            \n",
    "            new_workers_answers.loc[n, 'doc_id'] = 183468\n",
    "            new_workers_answers.loc[n, 'doc_statement'] = fever.loc[0, 'statement']\n",
    "            new_workers_answers.loc[n, 'doc_explanation'] = fever.loc[0, 'explanation_model']\n",
    "            new_workers_answers.loc[n, 'doc_label'] = fever.loc[0, 'label']\n",
    "        elif(explanation == fever.loc[1, 'explanation_model']):            \n",
    "            new_workers_answers.loc[n, 'doc_id'] = 185415\n",
    "            new_workers_answers.loc[n, 'doc_statement'] = fever.loc[1, 'statement']\n",
    "            new_workers_answers.loc[n, 'doc_explanation'] = fever.loc[1, 'explanation_model']\n",
    "            new_workers_answers.loc[n, 'doc_label'] = fever.loc[1, 'label']\n",
    "        elif(explanation == fever.loc[2, 'explanation_model']):            \n",
    "            new_workers_answers.loc[n, 'doc_id'] = 63527\n",
    "            new_workers_answers.loc[n, 'doc_statement'] = fever.loc[2, 'statement']\n",
    "            new_workers_answers.loc[n, 'doc_explanation'] = fever.loc[2, 'explanation_model']\n",
    "            new_workers_answers.loc[n, 'doc_label'] = fever.loc[2, 'label']\n",
    "        n += 1\n",
    "\n",
    "\n",
    "# Dataclass per gestire gli elementi degli HITs\n",
    "@dataclass\n",
    "\n",
    "class Elemento:\n",
    "    id: int\n",
    "    statement: str\n",
    "    explanation: str\n",
    "    label: str\n",
    "    type: str # E1,E2,E3 o G1,G2,G3\n",
    "\n",
    "def _init_(self, id: int, statement: str, explanation: str, label: str, type: str):\n",
    "    self.id = id\n",
    "    self.statement = statement\n",
    "    self.explanation = explanation\n",
    "    self.label = label\n",
    "    self.type = type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a4f6712-9aa6-4b15-8fd2-a438d5cd6f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "fever = pandas.read_csv('group_7-fabris_chivella_strazzi.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a2b54-50b8-43d3-96cd-e2bfc322bac3",
   "metadata": {},
   "source": [
    "# 3.Scrivete un Jupyter Notebook al fine di creare gli HITs del vostro task a partire dal dataset ricevuto, con le seguenti caratteristiche:\n",
    "1. Ogni HIT contiene 3 elementi\n",
    "2. Ogni elemento di un HIT ha 4 attributi:\n",
    "    - id:identificatoredellostatement\n",
    "    - statement:testodellostatement\n",
    "    - explanation:testodellaspiegazione\n",
    "    - label:etichettadellaspiegazione\n",
    "3. Due elementi su tre (2/3) di un HIT assegnano all’attributo explanation il valore di explanation_model\n",
    "4. Un elemento su tre (1/3) di un HIT assegnano all’attributo explanation il valore di explanation_human\n",
    "5. Ogni valore di explanation_model dev’essere valutato da 3 worker diversi\n",
    "6. Ogni valore di explanation_human dev’essere valutato da 2 worker diversi\n",
    "7. La posizione dei 3 elementi in un HIT deve essere casuale\n",
    "8. ll numero totale di HIT è pari a 12\n",
    "Si supponga che E1, E2, E3 indichino le spiegazioni generate, mentre G1, G2 e G3 quelle fornite da esseri umani. La seguente tabella mostra un possibile schema valido di allocazione di sei dei dodici HITs richiesti:\n",
    "| Posizione 1 | Posizione 2 | Posizione 3 |\n",
    "| ------------------ | ------------------ | ------------------ |\n",
    "| E1 | G1 | E2 |\n",
    "| G1 | E3 | E1 |\n",
    "| E2 | E1 | G2 |\n",
    "| E2 | G2 | E3 |\n",
    "| E3 | E1 | G3 |\n",
    "| G3 | E2 | E3 |\n",
    "| ... | ... | ... |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0797843-aca6-4d9b-918c-da74f504cea9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Per facilitare il lavoro in questa prima fase creo un dataframe e poi lo converto in json\n",
    "\n",
    "hits_array = [[0 for x in range(3)] for y in range(12)]\n",
    "\n",
    "# 1) disponigo casualmente a coppie di 2 le explanation_human come da consegna\n",
    "random12 = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "for x in range(3):\n",
    "    for count in range(2): # quota da raggiungere per ogni riga del csv\n",
    "        random_row = random.choice(random12)\n",
    "        random12.remove(random_row)\n",
    "        random_column = random.randint(0, 2)\n",
    "        \n",
    "        item = Elemento(fever.loc[x, \"id\"], fever.loc[x, \"statement\"], fever.loc[x, \"explanation_human\"], fever.loc[x, \"label\"],\"G\" + str(x+1))\n",
    "        \n",
    "        hits_array[random_row][random_column] = item\n",
    "\n",
    "# 2) riempio le righe restanti con explanation_human casuali\n",
    "for x in range(6):\n",
    "    random_row = random.choice(random12)\n",
    "    random12.remove(random_row)\n",
    "    random_column = random.randint(0, 2)\n",
    "    csv_row = random.randint(0, 2)\n",
    "    \n",
    "    item = Elemento(fever.loc[csv_row, \"id\"], fever.loc[csv_row, \"statement\"], fever.loc[csv_row, \"explanation_human\"], fever.loc[csv_row, \"label\"],\"G\" + str(csv_row+1))\n",
    "    \n",
    "    hits_array[random_row][random_column] = item\n",
    "\n",
    "# 3) in maniera simile al punto 1 inseriamo a gruppi di 3 elementi con explanation_model, assicurandoci che non finiscano nella stessa riga\n",
    "random12 = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "for x in range(3): # riga del csv\n",
    "    for count in range(3): # quota da raggiungere per ogni riga del csv\n",
    "        random_row = random.choice(random12)\n",
    "        random_column = random.randint(0, 2)\n",
    "        \n",
    "        if(hits_array[random_row][random_column] == 0 and check_row(hits_array, random_row, x)):\n",
    "            \n",
    "            item = Elemento(fever.loc[x, \"id\"], fever.loc[x, \"statement\"], fever.loc[x, \"explanation_model\"], fever.loc[x, \"label\"],\"E\" + str(x+1))\n",
    "            hits_array[random_row][random_column] = item\n",
    "\n",
    "# 4) riempio gli spazi vuoti con altri elementi con explanation_model, sempre assicurandoci che non finiscano nella stessa riga.\n",
    "# controllo elemento per elemento, quando troviamo una cella vuota la riempiamo\n",
    "n = 0\n",
    "for row in range(12):\n",
    "    for column in range(3):\n",
    "        \n",
    "        if(hits_array[row][column] == 0):\n",
    "            if(hits_array[row][0] != 0 and hits_array[row][0].type[:1] == 'E'):\n",
    "                n = int(hits_array[row][0].type[1:]) - 1\n",
    "            elif(hits_array[row][1] != 0 and hits_array[row][1].type[:1] == 'E'):\n",
    "                n = int(hits_array[row][1].type[1:]) - 1\n",
    "            elif(hits_array[row][2] != 0 and hits_array[row][2].type[:1] == 'E'):\n",
    "                n = int(hits_array[row][2].type[1:]) - 1\n",
    "            \n",
    "            csv_row = n \n",
    "            while(csv_row == n):\n",
    "                csv_row = random.randint(0, 2)\n",
    "            \n",
    "            item = Elemento(fever.loc[csv_row, \"id\"], fever.loc[csv_row, \"statement\"], fever.loc[csv_row, \"explanation_model\"], fever.loc[csv_row, \"label\"],\"E\" + str(csv_row+1))\n",
    "            hits_array[row][column] = item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "098460e6-3d09-456b-a417-4644377df558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data serialized to path: hits/hits.json\n"
     ]
    }
   ],
   "source": [
    "# Trasformo in json\n",
    "hits = []\n",
    "\n",
    "for i in range(12):\n",
    "    documents = []\n",
    "    unit = {\n",
    "        \"unit_id\": \"unit_\" + str(i+1),\n",
    "        \"token_input\": id_generator(),\n",
    "        \"token_output\": id_generator(),\n",
    "        \"documents_number\": 3,\n",
    "        \"documents\": []\n",
    "    }\n",
    "    for j in range(3):\n",
    "        document = {\n",
    "            \"id\": str(hits_array[i][j].id),\n",
    "            \"statement\": hits_array[i][j].statement,\n",
    "            \"explanation\": hits_array[i][j].explanation,\n",
    "            \"label\": hits_array[i][j].label\n",
    "        }\n",
    "        documents.append(document)\n",
    "    unit[\"documents\"] = documents\n",
    "    hits.append(unit)\n",
    "\n",
    "# Salvo il json\n",
    "serialize_json(\"hits\", \"hits.json\", hits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb26d38-dd82-4106-a0e0-767e9c9381cf",
   "metadata": {},
   "source": [
    "# Fase preparatoria dei dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b48db270-58d9-4968-99bb-bb8707ac3058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parte di preparazione\n",
    "\n",
    "# Importazione csv\n",
    "workers_acl = pandas.read_csv(f'{csv_dir}workers_acl.csv')\n",
    "workers_answers = pandas.read_csv(f'{csv_dir}workers_answers.csv')\n",
    "workers_dimensions_selection = pandas.read_csv(f'{csv_dir}workers_dimensions_selection.csv')\n",
    "workers_info = pandas.read_csv(f'{csv_dir}workers_info.csv')\n",
    "workers_notes = pandas.read_csv(f'{csv_dir}workers_notes.csv')\n",
    "workers_questionnaire = pandas.read_csv(f'{csv_dir}workers_questionnaire.csv')\n",
    "workers_urls = pandas.read_csv(f'{csv_dir}workers_urls.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d643cb9-5b8d-47df-b4b1-06c2842b75bc",
   "metadata": {},
   "source": [
    "### Prima di iniziare l'analisi dei dati abbiamo dovuto modellare i dataframe a causa di un numero troppo elevato di dati, dovuto a worker che non hanno completato i task, workers che non hanno inserito il token alla fine del task, worker che avevano fallito i controlli e altre problematiche simili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c850910c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[35])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[36])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[37])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[38])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[39])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:24: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[40])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[47])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[48])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_answers = new_workers_answers.append(worker_rows.loc[49])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:49: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[34])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[35])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:51: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[36])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[37])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:53: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[38])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[39])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:55: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[46])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:56: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[47])\n",
      "/var/folders/h7/73m3r7pd4116mzbw6fvwgl740000gn/T/ipykernel_2856/3758238363.py:57: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_workers_notes = new_workers_notes.append(worker_rows.loc[48])\n"
     ]
    }
   ],
   "source": [
    "# Modifichiamo il dataframe workers_answers in modo da mantenere i dati dei workers corretti ed eliminare i dati non necessari.\n",
    "id_list = ['A2FA30PTJ8OHRA', 'A3GMWT12HZ8BO1', 'A2V54TYNYXD078', 'A338IHJHCEN2DH', 'A32XES1XS1PIYF', 'CLYQ7NB2JJXXGG', 'A2N1GA8PJDDA6P']\n",
    "\n",
    "new_workers_answers = pandas.DataFrame()\n",
    "\n",
    "for j in range(len(id_list)):\n",
    "    worker_rows = workers_answers.loc[workers_answers['worker_id'] == id_list[j]]\n",
    "    length = len(worker_rows)\n",
    "    # Rinomino le rows per poter iterare\n",
    "    rownames = worker_rows.index.values\n",
    "    for i in range(length):\n",
    "        rownames[i] = i\n",
    "    for i in range(length):\n",
    "        if(worker_rows.loc[i, 'try_last'] == worker_rows.loc[i, 'try_current']):\n",
    "            new_workers_answers = new_workers_answers.append(worker_rows.loc[i])\n",
    "\n",
    "# Aggiungiamo manualmente delle righe per problematiche nel csv\n",
    "worker_rows = workers_answers.loc[workers_answers['worker_id'] == 'A21YKS9HCFVZ9H']\n",
    "new_workers_answers = new_workers_answers.append(worker_rows.loc[35])\n",
    "new_workers_answers = new_workers_answers.append(worker_rows.loc[36])\n",
    "new_workers_answers = new_workers_answers.append(worker_rows.loc[37])\n",
    "new_workers_answers = new_workers_answers.append(worker_rows.loc[38])\n",
    "new_workers_answers = new_workers_answers.append(worker_rows.loc[39])\n",
    "new_workers_answers = new_workers_answers.append(worker_rows.loc[40])\n",
    "new_workers_answers = new_workers_answers.append(worker_rows.loc[47])\n",
    "new_workers_answers = new_workers_answers.append(worker_rows.loc[48])\n",
    "new_workers_answers = new_workers_answers.append(worker_rows.loc[49])\n",
    "\n",
    "rownames = new_workers_answers.index.values\n",
    "for i in range(len(new_workers_answers)):\n",
    "    rownames[i] = i\n",
    "\n",
    "# In maniera analoga modifichiamo il dataframe workers_notes\n",
    "new_workers_notes = pandas.DataFrame()\n",
    "\n",
    "for j in range(len(id_list)):\n",
    "    worker_rows = workers_notes.loc[workers_notes['worker_id'] == id_list[j]]\n",
    "    length = len(worker_rows)\n",
    "    # Rinomino le rows per poter iterare\n",
    "    rownames = worker_rows.index.values\n",
    "    for i in range(length):\n",
    "        rownames[i] = i\n",
    "    for i in range(length):\n",
    "        if(worker_rows.loc[i, 'try_last'] == worker_rows.loc[i, 'try_current']):\n",
    "            new_workers_notes = new_workers_notes.append(worker_rows.loc[i])\n",
    "\n",
    "# Aggiungiamo manualmente delle righe per problematiche nel csv\n",
    "worker_rows = workers_notes.loc[workers_notes['worker_id'] == 'A21YKS9HCFVZ9H']\n",
    "new_workers_notes = new_workers_notes.append(worker_rows.loc[34])\n",
    "new_workers_notes = new_workers_notes.append(worker_rows.loc[35])\n",
    "new_workers_notes = new_workers_notes.append(worker_rows.loc[36])\n",
    "new_workers_notes = new_workers_notes.append(worker_rows.loc[37])\n",
    "new_workers_notes = new_workers_notes.append(worker_rows.loc[38])\n",
    "new_workers_notes = new_workers_notes.append(worker_rows.loc[39])\n",
    "new_workers_notes = new_workers_notes.append(worker_rows.loc[46])\n",
    "new_workers_notes = new_workers_notes.append(worker_rows.loc[47])\n",
    "new_workers_notes = new_workers_notes.append(worker_rows.loc[48])\n",
    "\n",
    "rownames = new_workers_notes.index.values\n",
    "for i in range(len(new_workers_notes)):\n",
    "    rownames[i] = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc68b570-e517-4a82-b5fb-b06f1e518d26",
   "metadata": {},
   "source": [
    "### Dopo il dowload gli statement, explanation, label e id di alcuni worker non sono stati salvati correttamente in workers_answers, mentre in workers_notes si.\n",
    "### Grazie alle note in workers_notes possiamo risalire agli elementi corretti e sistemare workers_answers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d75b5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulizia elementi problematici\n",
    "new_workers_notes.loc[0, 'note_text_left'] = ''  #note_text_left aveva come valore NaN\n",
    "\n",
    "new_workers_notes.loc[1, 'note_text_left'] = new_workers_notes.loc[1, 'note_text_left'][1:] \n",
    "new_workers_notes.loc[1, 'note_text_right'] = new_workers_notes.loc[1, 'note_text_right'][:-1] \n",
    "new_workers_notes.loc[1, 'note_text_left'] = new_workers_notes.loc[1, 'note_text_left'][:67] + 'ém' + new_workers_notes.loc[1, 'note_text_left'][70:]# è cambiata a causa di passaggio da mac a windows\n",
    "\n",
    "new_workers_notes.loc[3, 'note_text_left'] = new_workers_notes.loc[3, 'note_text_left'][1:] \n",
    "new_workers_notes.loc[3, 'note_text_right'] = new_workers_notes.loc[3, 'note_text_right'][:-1] \n",
    "\n",
    "new_workers_notes.loc[4, 'note_text_left'] = '\"' + new_workers_notes.loc[4, 'note_text_left'][2:] \n",
    "new_workers_notes.loc[4, 'note_text_right'] = new_workers_notes.loc[4, 'note_text_right'][:-2] + '\"'\n",
    "\n",
    "new_workers_notes.loc[5, 'note_text_left'] = fever.loc[1, 'explanation_model'][:279]\n",
    "new_workers_notes.loc[5, 'note_text_right'] = fever.loc[1, 'explanation_model'][301:]\n",
    "\n",
    "new_workers_notes.loc[6, 'note_text_left'] = new_workers_notes.loc[6, 'note_text_left'][1:] \n",
    "new_workers_notes.loc[6, 'note_text_right'] = new_workers_notes.loc[6, 'note_text_right'][:-1]\n",
    "\n",
    "new_workers_notes.loc[7, 'note_text_left'] = new_workers_notes.loc[7, 'note_text_left'][1:] \n",
    "new_workers_notes.loc[7, 'note_text_right'] = new_workers_notes.loc[7, 'note_text_right'][:-1]\n",
    "new_workers_notes.loc[7, 'note_text_right'] = new_workers_notes.loc[7, 'note_text_right'][:12] + 'é' + new_workers_notes.loc[7, 'note_text_right'][14:]# è cambiata a causa di passaggio da mac a windows\n",
    "\n",
    "new_workers_notes.loc[8, 'note_text_left'] = new_workers_notes.loc[8, 'note_text_left'][1:] \n",
    "new_workers_notes.loc[8, 'note_text_right'] = new_workers_notes.loc[8, 'note_text_right'][:-1]\n",
    "\n",
    "new_workers_notes.loc[10, 'note_text_left'] = new_workers_notes.loc[10, 'note_text_left'][1:] \n",
    "new_workers_notes.loc[10, 'note_text_right'] = new_workers_notes.loc[10, 'note_text_right'][:-1]\n",
    "\n",
    "new_workers_notes.loc[13, 'note_text_left'] = new_workers_notes.loc[13, 'note_text_left'][1:] \n",
    "new_workers_notes.loc[13, 'note_text_right'] = new_workers_notes.loc[13, 'note_text_right'][:-1]\n",
    "new_workers_notes.loc[13, 'note_text_raw'] = new_workers_notes.loc[13, 'note_text_raw'][:67]+ 'ém' + new_workers_notes.loc[13, 'note_text_raw'][68:] # è cambiata a causa di passaggio da mac a windows\n",
    "\n",
    "new_workers_notes.loc[15, 'note_text_left'] = new_workers_notes.loc[15, 'note_text_left'][1:] \n",
    "new_workers_notes.loc[15, 'note_text_right'] = new_workers_notes.loc[15, 'note_text_right'][:-1]\n",
    "new_workers_notes.loc[15, 'note_text_left'] = new_workers_notes.loc[15, 'note_text_left'][:67] + 'ém' + new_workers_notes.loc[15, 'note_text_left'][70:] \n",
    "\n",
    "new_workers_notes.loc[26, 'note_text_left'] = new_workers_notes.loc[26, 'note_text_left'][1:] \n",
    "new_workers_notes.loc[26, 'note_text_right'] = new_workers_notes.loc[26, 'note_text_right'][:-1]\n",
    "new_workers_notes.loc[26, 'note_text_raw'] = new_workers_notes.loc[26, 'note_text_raw'][:10] + 'é' + new_workers_notes.loc[26, 'note_text_raw'][10:]\n",
    "\n",
    "new_workers_notes.loc[27, 'note_text_left'] = new_workers_notes.loc[27, 'note_text_left'][1:] \n",
    "new_workers_notes.loc[27, 'note_text_right'] = new_workers_notes.loc[27, 'note_text_right'][:-1] \n",
    "new_workers_notes.loc[27, 'note_text_raw'] = new_workers_notes.loc[27, 'note_text_raw'][:-4] + '- ' + new_workers_notes.loc[27, 'note_text_raw'][-4:]# Trattino mancante\n",
    "\n",
    "new_workers_notes.loc[28, 'note_text_left'] = new_workers_notes.loc[28, 'note_text_left'][1:] \n",
    "new_workers_notes.loc[28, 'note_text_right'] = new_workers_notes.loc[28, 'note_text_right'][:-1] \n",
    "\n",
    "new_workers_notes.loc[29, 'note_text_left'] = new_workers_notes.loc[29, 'note_text_left'][1:] \n",
    "new_workers_notes.loc[29, 'note_text_right'] = new_workers_notes.loc[29, 'note_text_right'][:-1] \n",
    "\n",
    "new_workers_notes.loc[30, 'note_text_left'] = new_workers_notes.loc[30, 'note_text_left'][1:] \n",
    "new_workers_notes.loc[30, 'note_text_right'] = new_workers_notes.loc[30, 'note_text_right'][:-1] \n",
    "\n",
    "new_workers_notes.loc[31, 'note_text_left'] = new_workers_notes.loc[31, 'note_text_left'][1:] \n",
    "new_workers_notes.loc[31, 'note_text_right'] = new_workers_notes.loc[31, 'note_text_right'][:-1] \n",
    "new_workers_notes.loc[31, 'note_text_left'] = new_workers_notes.loc[31, 'note_text_left'] [:5] + ' ' + new_workers_notes.loc[31, 'note_text_left'][5:8] + ' of ' +  new_workers_notes.loc[31, 'note_text_left'][11:] # Spazi mancanti\n",
    "new_workers_notes.loc[31, 'note_text_raw'] = new_workers_notes.loc[31, 'note_text_raw'][:3] + ' ' + new_workers_notes.loc[31, 'note_text_raw'][3:]\n",
    "\n",
    "new_workers_notes.loc[32, 'note_text_left'] = new_workers_notes.loc[32, 'note_text_left'][1:] \n",
    "new_workers_notes.loc[32, 'note_text_right'] = new_workers_notes.loc[32, 'note_text_right'][:-1] \n",
    "\n",
    "new_workers_notes.loc[33, 'note_text_left'] = new_workers_notes.loc[33, 'note_text_left'][1:] \n",
    "new_workers_notes.loc[33, 'note_text_right'] = new_workers_notes.loc[33, 'note_text_right'][:-1] \n",
    "\n",
    "new_workers_notes.loc[34, 'note_text_left'] = new_workers_notes.loc[34, 'note_text_left'][1:] \n",
    "new_workers_notes.loc[34, 'note_text_right'] = new_workers_notes.loc[34, 'note_text_right'][:-1] \n",
    "\n",
    "answers_fix(0, 35, new_workers_answers, new_workers_notes, fever) # Modifichiamo statement, explanation, label e id grazie alle note che abbiamo sistemato\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7ece0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lunghezza precedente workers_answers: 85\n",
      "Lunghezza nuovo workers_answers: 36\n",
      "Lunghezza precedente workers_notes: 83\n",
      "Lunghezza nuovo workers_notes: 36\n"
     ]
    }
   ],
   "source": [
    "# Salviamo i nuovi dataframe finalmente hanno 36 righe\n",
    "\n",
    "old_workers_answers = workers_answers\n",
    "old_workers_notes = workers_notes\n",
    "\n",
    "workers_answers = new_workers_answers\n",
    "workers_notes = new_workers_notes\n",
    "\n",
    "print(f'Lunghezza precedente workers_answers: {len(old_workers_answers)}')\n",
    "print(f'Lunghezza nuovo workers_answers: {len(workers_answers)}')\n",
    "print(f'Lunghezza precedente workers_notes: {len(old_workers_notes)}')\n",
    "print(f'Lunghezza nuovo workers_notes: {len(workers_notes)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880b8398-eda6-46f9-a51b-6804502fde7e",
   "metadata": {},
   "source": [
    "### Infine alcuni valori riguardanti il tempo impiegato dai worker per completare i task erano sostituiti da NaN, pensiamo sia dovuto al tempo minimo da passare su ogni pagina, da noi impostato\n",
    "### Per questo sostituiamo tutti i valori NaN con il tempo minimo di 30 secondi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3efeaa0-41ed-4f8b-b6e4-24ff3ebfefb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(workers_answers)):\n",
    "    if(math.isnan(workers_answers.loc[i, 'doc_time_elapsed'])):\n",
    "        workers_answers.loc[i, 'doc_time_elapsed'] = 30.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dfeed9-8735-4937-b534-4ded46b1ee09",
   "metadata": {},
   "source": [
    "# 9.Calcolate il Percent Agreement tra worker per i valori forniti rispetto a ciascuna dimensione categoriale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b6cb469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inizializzazioni di Dataframe dove inseriamo le righe del csv originale con lo stesso ID e manipolazione dei df\n",
    "statement_1 = pandas.DataFrame()\n",
    "statement_2 = pandas.DataFrame()\n",
    "statement_3 = pandas.DataFrame()\n",
    "\n",
    "statement_1 = workers_answers.loc[workers_answers['doc_id'] == 183468]\n",
    "statement_2 = workers_answers.loc[workers_answers['doc_id'] == 185415]\n",
    "statement_3 = workers_answers.loc[workers_answers['doc_id'] == 63527]\n",
    "\n",
    "statement_1_rownames = statement_1.index.values\n",
    "for i in range(len(statement_1.index)):\n",
    "    statement_1_rownames[i] = i\n",
    "\n",
    "statement_2_rownames = statement_2.index.values\n",
    "for i in range(len(statement_2.index)):\n",
    "    statement_2_rownames[i] = i\n",
    "\n",
    "statement_3_rownames = statement_3.index.values\n",
    "for i in range(len(statement_3.index)):\n",
    "    statement_3_rownames[i] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa84e72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Truthfulness 1</th>\n",
       "      <th>Truthfulness 2</th>\n",
       "      <th>Explanation quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Statement 1</th>\n",
       "      <td>0.445455</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statement 2</th>\n",
       "      <td>0.216783</td>\n",
       "      <td>0.237762</td>\n",
       "      <td>0.160839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statement 3</th>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.370370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Truthfulness 1  Truthfulness 2  Explanation quality\n",
       "Statement 1        0.445455        0.436364             0.181818\n",
       "Statement 2        0.216783        0.237762             0.160839\n",
       "Statement 3        0.240741        0.370370             0.370370"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inizializziamo un dataframe dove inserire le explanation in base alla lunghezza percentuale delle note e un dataframe per effettuare i calcoli\n",
    "\n",
    "percent_agreement = pandas.DataFrame(0, columns = ['Truthfulness 1', 'Truthfulness 2', 'Explanation quality'], index = ['Statement 1', 'Statement 2', 'Statement 3'])\n",
    "\n",
    "# Sommiamo le lunghezze di tutte le note appartenenti ad una determinata explanation e salvo il risultato in text_percentage\n",
    "statements = [statement_1, statement_2, statement_3]\n",
    "\n",
    "for j in range(len(statements)):\n",
    "    workers_pairs = 0\n",
    "    for i in range (len(statements[j].index)):\n",
    "        ground_truth_compare_statement_truth1 = statements[j].loc[i, 'doc_truthfulness1_value']\n",
    "        ground_truth_compare_statement_truth2 = statements[j].loc[i, 'doc_truthfulness2_value']\n",
    "        ground_truth_compare_statement_explanation = statements[j].loc[i, 'doc_explanationquality_value']\n",
    "        n = j+1\n",
    "        while (n < (len(statements[j].index))):\n",
    "            confronted_worker_statement_truth1 = statements[j].loc[n, 'doc_truthfulness1_value']\n",
    "            confronted_worker_statement_truth2 = statements[j].loc[n, 'doc_truthfulness2_value']\n",
    "            confronted_worker_statement_explanation = statements[j].loc[n, 'doc_explanationquality_value']\n",
    "            if(ground_truth_compare_statement_truth1 == confronted_worker_statement_truth1):\n",
    "                percent_agreement.loc[f'Statement {j+1}', 'Truthfulness 1'] += 1\n",
    "            if(ground_truth_compare_statement_truth2 == confronted_worker_statement_truth2):\n",
    "                percent_agreement.loc[f'Statement {j+1}', 'Truthfulness 2'] += 1\n",
    "            in_same_interval(percent_agreement, ground_truth_compare_statement_explanation, confronted_worker_statement_explanation, j+1)\n",
    "            n += 1\n",
    "            workers_pairs += 1\n",
    "    percent_agreement.loc[f'Statement {j+1}', 'Truthfulness 1'] = percent_agreement.loc[f'Statement {j+1}', 'Truthfulness 1'] / workers_pairs\n",
    "    percent_agreement.loc[f'Statement {j+1}', 'Truthfulness 2'] = percent_agreement.loc[f'Statement {j+1}', 'Truthfulness 2'] / workers_pairs\n",
    "    percent_agreement.loc[f'Statement {j+1}', 'Explanation quality'] = percent_agreement.loc[f'Statement {j+1}', 'Explanation quality'] / workers_pairs\n",
    "\n",
    "percent_agreement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2210d248-b96b-4a0b-a722-5f899c9b65d3",
   "metadata": {},
   "source": [
    "# 10.Calcolate la percentuale media di testo annotato per ciascuna spiegazione\n",
    "1. Ordinate le spiegazioni sulla base di tale parametro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c784d68a-922c-4b31-aea9-422015338ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inizializzazioni di Dataframe dove inseriamo le righe del csv con le stesse explanation\n",
    "explanation_human_1 = pandas.DataFrame()\n",
    "explanation_human_2 = pandas.DataFrame()\n",
    "explanation_human_3 = pandas.DataFrame()\n",
    "explanation_model_1 = pandas.DataFrame()\n",
    "explanation_model_2 = pandas.DataFrame()\n",
    "explanation_model_3 = pandas.DataFrame()\n",
    "\n",
    "explanation_human_1 = workers_answers.loc[workers_answers['doc_explanation'] == fever.loc[0, 'explanation_human']]\n",
    "explanation_model_1 = workers_answers.loc[workers_answers['doc_explanation'] == fever.loc[0, 'explanation_model']]\n",
    "explanation_human_2 = workers_answers.loc[workers_answers['doc_explanation'] == fever.loc[1, 'explanation_human']]\n",
    "explanation_model_2 = workers_answers.loc[workers_answers['doc_explanation'] == fever.loc[1, 'explanation_model']]\n",
    "explanation_human_3 = workers_answers.loc[workers_answers['doc_explanation'] == fever.loc[2, 'explanation_human']]\n",
    "explanation_model_3 = workers_answers.loc[workers_answers['doc_explanation'] == fever.loc[2, 'explanation_model']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7e1c935-b053-4cd0-abf6-07b1feabb2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explanation human 3</td>\n",
       "      <td>0.259539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Explanation human 1</td>\n",
       "      <td>0.243948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explanation human 2</td>\n",
       "      <td>0.145162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Explanation model 1</td>\n",
       "      <td>0.143902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation model 3</td>\n",
       "      <td>0.131028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Explanation model 2</td>\n",
       "      <td>0.07642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Order     Value\n",
       "1  Explanation human 3  0.259539\n",
       "2  Explanation human 1  0.243948\n",
       "3  Explanation human 2  0.145162\n",
       "4  Explanation model 1  0.143902\n",
       "5  Explanation model 3  0.131028\n",
       "6  Explanation model 2   0.07642"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inizializziamo un dataframe dove inserire le explanation in base alla lunghezza percentuale delle note e un dataframe per effettuare i calcoli\n",
    "text_percentage = pandas.DataFrame(0, columns = ['Explanation human 1', 'Explanation human 2', 'Explanation human 3', 'Explanation model 1', 'Explanation model 2', 'Explanation model 3'], index = ['percentage'])\n",
    "\n",
    "percentage_order = pandas.DataFrame(columns = ['Order', 'Value'])\n",
    "\n",
    "# Sommiamo le lunghezze di tutte le note appartenenti ad una determinata explanation e salvo il risultato in text_percentage\n",
    "explanation_humans = [explanation_human_1, explanation_human_2, explanation_human_3]\n",
    "\n",
    "for j in range(len(explanation_humans)):\n",
    "    for i in range (len(explanation_humans[j].index)):\n",
    "        text_percentage.loc['percentage', f'Explanation human {j+1}'] += len(workers_notes.loc[explanation_humans[j].index.values[i], 'note_text_current']) \n",
    "    # Otteniamo la media\n",
    "    text_percentage.loc['percentage', f'Explanation human {j+1}'] /= i+1 \n",
    "    # Otteniamo la percentuale\n",
    "    text_percentage.loc['percentage', f'Explanation human {j+1}'] /= (workers_notes.loc[explanation_humans[j].index.values[0], 'note_index_end'] + len(workers_notes.loc[explanation_humans[j].index.values[0], 'note_text_right']))\n",
    "\n",
    "explanation_models = [explanation_model_1, explanation_model_2, explanation_model_3]\n",
    "\n",
    "for j in range(len(explanation_models)):\n",
    "    for i in range (len(explanation_models[j].index)):\n",
    "        text_percentage.loc['percentage', f'Explanation model {j+1}'] += len(workers_notes.loc[explanation_models[j].index.values[i], 'note_text_current']) \n",
    "    # Otteniamo la media\n",
    "    text_percentage.loc['percentage', f'Explanation model {j+1}'] /= i+1 \n",
    "    # Otteniamo la percentuale\n",
    "    text_percentage.loc['percentage', f'Explanation model {j+1}'] /= workers_notes.loc[explanation_models[j].index.values[i], 'note_index_end'] + len(workers_notes.loc[explanation_models[j].index.values[i], 'note_text_right'])\n",
    "\n",
    "# sommiamo tutte le lunghezze ottenute e uso questo valore per dividere ciascun elemento del dataframe ottenendo la percentuale  \n",
    "text_percentage /= text_percentage.loc['percentage'].sum()\n",
    "\n",
    "# troviamo l'elemento con la percentuale maggiore, lo inseriamo nel DataFrame apposito e lo togliamo dal dataframe precedente\n",
    "for i in range(5):\n",
    "    percentage_order.loc[i+1, 'Order'] = text_percentage.loc['percentage'].idxmax()\n",
    "    percentage_order.loc[i+1, 'Value'] = text_percentage.loc['percentage'].max()\n",
    "    text_percentage = text_percentage.drop(columns = [text_percentage.loc['percentage'].idxmax()])\n",
    "percentage_order.loc[6, 'Order'] = text_percentage.loc['percentage'].idxmax()\n",
    "percentage_order.loc[6, 'Value'] = text_percentage.loc['percentage'].max()\n",
    "\n",
    "percentage_order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bca800a-199e-41f5-979e-4e8be9c79988",
   "metadata": {},
   "source": [
    "# 11.Determinate il numero di volte in cui i worker aggiornano l’annotazione proposta per ciascuna spiegazione\n",
    "1. Costruite un ranking delle spiegazioni sulla base di tale parametro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bf90fc2-9d3b-4ebf-90d8-a05a3de65d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Explanation</th>\n",
       "      <th>Number of updates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>explanation model 3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>explanation model 2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>explanation human 1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>explanation model 1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>explanation human 2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>explanation human 3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Explanation Number of updates\n",
       "1  explanation model 3                17\n",
       "2  explanation model 2                12\n",
       "3  explanation human 1                10\n",
       "4  explanation model 1                10\n",
       "5  explanation human 2                 8\n",
       "6  explanation human 3                 3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inizializziamo un dataframe dove inserire le explanation in base alla lunghezza percentuale delle note e un dataframe per effettuare i calcoli\n",
    "notes_updated = pandas.DataFrame(0, columns = ['explanation human 1', 'explanation human 2', 'explanation human 3', 'explanation model 1', 'explanation model 2', 'explanation model 3'], index = ['updated notes'])\n",
    "\n",
    "update_values = pandas.DataFrame(columns = ['Explanation', 'Number of updates'])\n",
    "\n",
    "# Usando il parametro note_deleted vediamo se le annotazioni sono state selezionate solo una volta\n",
    "for j in range(len(explanation_humans)):\n",
    "    for i in range (len(explanation_humans[j].index)):\n",
    "        if(workers_notes.loc[explanation_humans[j].index.values[i], 'note_deleted'] == False):\n",
    "            notes_updated.loc['updated notes', f'explanation human {j+1}'] += 1\n",
    "        else:\n",
    "            notes_updated.loc['updated notes', f'explanation human {j+1}'] += 2\n",
    "\n",
    "for j in range(len(explanation_models)):\n",
    "    for i in range (len(explanation_models[j].index)):\n",
    "        if(workers_notes.loc[explanation_models[j].index.values[i], 'note_deleted'] == False):\n",
    "            notes_updated.loc['updated notes', f'explanation model {j+1}'] += 1\n",
    "        else:\n",
    "            notes_updated.loc['updated notes', f'explanation model {j+1}'] += 2\n",
    "\n",
    "# troviamo l'elemento con il numero di update maggiore, lo inseriamo nel DataFrame apposito e lo togliamo dal dataframe precedente\n",
    "for i in range(5):\n",
    "    update_values.loc[i+1, 'Explanation'] = notes_updated.loc['updated notes'].idxmax()\n",
    "    update_values.loc[i+1, 'Number of updates'] = notes_updated.loc['updated notes'].max()\n",
    "    notes_updated = notes_updated.drop(columns = [notes_updated.loc['updated notes'].idxmax()])\n",
    "update_values.loc[6, 'Explanation'] = notes_updated.loc['updated notes'].idxmax()\n",
    "update_values.loc[6, 'Number of updates'] = notes_updated.loc['updated notes'].max()\n",
    "\n",
    "update_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccef57a9-169f-42e3-9c58-d94f8f159353",
   "metadata": {},
   "source": [
    "# 12.Calcolate il tempo medio impiegato dai worker per valutare ciascun elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f91ce75f-db21-4cd9-ae33-29693e046cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statement 1</th>\n",
       "      <th>Statement 2</th>\n",
       "      <th>Statement 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>185.386364</td>\n",
       "      <td>154.372308</td>\n",
       "      <td>149.969167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Statement 1  Statement 2  Statement 3\n",
       "Average   185.386364   154.372308   149.969167"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcoliamo e inseriamo in un dataframe apposito, il tempo medio di risoluzione dei task in base a quale statement viene analizzato\n",
    "average = pandas.DataFrame(0, columns = ['Statement 1', 'Statement 2', 'Statement 3'], index = ['Average'])\n",
    "\n",
    "for j in range (len(statements)):\n",
    "    average_current = 0\n",
    "    for i in range (len(statements[j])):\n",
    "        average_current += statements[j].loc[i, 'doc_time_elapsed']        \n",
    "    \n",
    "    average_current /= len(statements[j])\n",
    "    average.loc['Average', f'Statement {j+1}'] = average_current\n",
    "\n",
    "average\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d96131-494e-4701-b0a7-d7112d7d3a7a",
   "metadata": {},
   "source": [
    "# 13.Aggiungete eventuali altre analisi che ritenete opportune ed utili"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded1df3b",
   "metadata": {},
   "source": [
    "### Abbiamo calcolato e confrontato il punteggio medio di ogni dimensione categoriale di ogni explanation, in modo da poter vedere e confrontare i valori medi assegnati alle explanation, riguardanti gli stessi statement, generati da un umano e quelli generati dalla macchina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eab40630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Explanation human 1</th>\n",
       "      <th>Explanation model 1</th>\n",
       "      <th>Explanation human 2</th>\n",
       "      <th>Explanation model 2</th>\n",
       "      <th>Explanation human 3</th>\n",
       "      <th>Explanation model 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Truthfulness 1</th>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Truthfulness 2</th>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Explanation quality</th>\n",
       "      <td>57.333333</td>\n",
       "      <td>31.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>84.777778</td>\n",
       "      <td>53.0</td>\n",
       "      <td>84.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Explanation human 1  Explanation model 1  \\\n",
       "Truthfulness 1                  3.333333                  3.4   \n",
       "Truthfulness 2                  3.833333                  3.8   \n",
       "Explanation quality            57.333333                 31.4   \n",
       "\n",
       "                     Explanation human 2  Explanation model 2  \\\n",
       "Truthfulness 1                       0.5             3.888889   \n",
       "Truthfulness 2                       1.0             3.444444   \n",
       "Explanation quality                 12.0            84.777778   \n",
       "\n",
       "                     Explanation human 3  Explanation model 3  \n",
       "Truthfulness 1                       1.5                  3.1  \n",
       "Truthfulness 2                       2.0                  3.9  \n",
       "Explanation quality                 53.0                 84.9  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Punteggio medio di ogni dimensione categoriale di ogni explanation\n",
    "average_explanation_values = pandas.DataFrame(0, columns = ['Explanation human 1', 'Explanation model 1', 'Explanation human 2', 'Explanation model 2', 'Explanation human 3', 'Explanation model 3'], index = ['Truthfulness 1', 'Truthfulness 2', 'Explanation quality'])\n",
    "\n",
    "average_explanation_quality_values(average_explanation_values, explanation_human_1, 'human 1')\n",
    "average_explanation_quality_values(average_explanation_values, explanation_model_1, 'model 1')\n",
    "average_explanation_quality_values(average_explanation_values, explanation_human_2, 'human 2')\n",
    "average_explanation_quality_values(average_explanation_values, explanation_model_2, 'model 2')\n",
    "average_explanation_quality_values(average_explanation_values, explanation_human_3, 'human 3')\n",
    "average_explanation_quality_values(average_explanation_values, explanation_model_3, 'model 3')\n",
    "\n",
    "average_explanation_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061f2983",
   "metadata": {},
   "source": [
    "### Abbiamo calcolato la percentuale di testo selezionato per ogni explanation rispetto alla quantità di testo selezionato complessivamente tra tutte le explanation (punto 10 modificato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c7a1e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explanation model 2</td>\n",
       "      <td>0.361621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Explanation model 3</td>\n",
       "      <td>0.294807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explanation model 1</td>\n",
       "      <td>0.165294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Explanation human 1</td>\n",
       "      <td>0.098797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation human 2</td>\n",
       "      <td>0.048132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Explanation human 3</td>\n",
       "      <td>0.031349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Order     Value\n",
       "1  Explanation model 2  0.361621\n",
       "2  Explanation model 3  0.294807\n",
       "3  Explanation model 1  0.165294\n",
       "4  Explanation human 1  0.098797\n",
       "5  Explanation human 2  0.048132\n",
       "6  Explanation human 3  0.031349"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inizializziamo un dataframe dove inserire le explanation in base alla lunghezza percentuale delle note e un dataframe per effettuare i calcoli\n",
    "text_percentage = pandas.DataFrame(0, columns = ['Explanation human 1', 'Explanation human 2', 'Explanation human 3', 'Explanation model 1', 'Explanation model 2', 'Explanation model 3'], index = ['percentage'])\n",
    "\n",
    "percentage_order = pandas.DataFrame(columns = ['Order', 'Value'])\n",
    "\n",
    "# Sommiamo le lunghezze di tutte le note appartenenti ad una determinata explanation e salvo il risultato in text_percentage\n",
    "explanation_humans = [explanation_human_1, explanation_human_2, explanation_human_3]\n",
    "\n",
    "for j in range(len(explanation_humans)):\n",
    "    for i in range (len(explanation_humans[j].index)):\n",
    "        text_percentage.loc['percentage', f'Explanation human {j+1}'] += len(workers_notes.loc[explanation_humans[j].index.values[i], 'note_text_current']) \n",
    "\n",
    "explanation_models = [explanation_model_1, explanation_model_2, explanation_model_3]\n",
    "\n",
    "for j in range(len(explanation_models)):\n",
    "    for i in range (len(explanation_models[j].index)):\n",
    "        text_percentage.loc['percentage', f'Explanation model {j+1}'] += len(workers_notes.loc[explanation_models[j].index.values[i], 'note_text_current']) \n",
    "\n",
    "# sommiamo tutte le lunghezze ottenute e uso questo valore per dividere ciascun elemento del dataframe ottenendo la percentuale  \n",
    "text_percentage /= text_percentage.loc['percentage'].sum()\n",
    "\n",
    "# troviamo l'elemento con la percentuale maggiore, lo inseriamo nel DataFrame apposito e lo togliamo dal dataframe precedente\n",
    "for i in range(5):\n",
    "    percentage_order.loc[i+1, 'Order'] = text_percentage.loc['percentage'].idxmax()\n",
    "    percentage_order.loc[i+1, 'Value'] = text_percentage.loc['percentage'].max()\n",
    "    text_percentage = text_percentage.drop(columns = [text_percentage.loc['percentage'].idxmax()])\n",
    "percentage_order.loc[6, 'Order'] = text_percentage.loc['percentage'].idxmax()\n",
    "percentage_order.loc[6, 'Value'] = text_percentage.loc['percentage'].max()\n",
    "\n",
    "percentage_order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b2d91-a8da-4c85-abda-daf941dc55cf",
   "metadata": {},
   "source": [
    "### Abbiamo calcolato il tempo medio di esecuzione di tutti i task (punto 12 modificato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9cf42ae-2808-4ff1-a6aa-ddd5e7cec4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162.38111111111104"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tempo medio completamento task\n",
    "average = 0\n",
    "\n",
    "for i in range (len(workers_answers.index)):\n",
    "    average += workers_answers.loc[i, 'doc_time_elapsed']\n",
    "\n",
    "average /= len(workers_answers.index)\n",
    "\n",
    "average\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
